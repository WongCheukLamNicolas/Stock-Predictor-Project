# -*- coding: utf-8 -*-
"""COSC 4P80 GROUP WORK GRU CODE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rXVQXSLIG3Qq3Fj4phUZFJ-LzGMAPZno
"""

#NAME: ADDEY JNR PRINCE ISAAC KOFI
import yfinance as yf
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import math
import matplotlib.pyplot as plt
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense
from tensorflow.keras.optimizers import Adamax, RMSprop, SGD, Ftrl

#  Download data
data = yf.download("AAPL", start="2020-01-01", end="2024-12-31")
data = data[["Close"]]

#  Normalize
scaler = MinMaxScaler()
data["Close"] = scaler.fit_transform(np.array(data["Close"]).reshape(-1,1))

#  Split
train_size = int(len(data)*0.8)
train_data, test_data = data[:train_size], data[train_size:]

#  Dataset creation
def create_dataset(dataset, look_back=60):
    X, Y = [], []
    for i in range(len(dataset) - look_back - 1):
        X.append(dataset['Close'][i:i+look_back].values)
        Y.append(dataset['Close'].iloc[i+look_back])
    return np.array(X), np.array(Y)

look_back = 60
X_train, Y_train = create_dataset(train_data, look_back)
X_test, Y_test = create_dataset(test_data, look_back)
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))

#  Optimizers
optimizers = {
    'Adamax': Adamax(learning_rate=0.001),
    'Ftrl': Ftrl(learning_rate=0.001),
    'SGD': SGD(learning_rate=0.01, momentum=0.9)
}

#  Helper functions
def build_gru_model(input_shape):
    model = Sequential()
    model.add(GRU(50, return_sequences=True, input_shape=input_shape))
    model.add(GRU(50))
    model.add(Dense(1))
    return model

def compute_direction_accuracy(actual, predicted):
    actual_dir = np.sign(np.diff(actual.flatten()))
    predicted_dir = np.sign(np.diff(predicted.flatten()))
    correct = (actual_dir == predicted_dir).sum()
    avg_success = correct / len(actual_dir) * 100
    return avg_success

def compute_best_success(actual, predicted, window=20):
    actual = actual.flatten()
    predicted = predicted.flatten()
    best_rate = 0
    for i in range(len(actual)-window):
        window_actual = actual[i:i+window]
        window_pred = predicted[i:i+window]
        rate = compute_direction_accuracy(window_actual, window_pred)
        if rate > best_rate:
            best_rate = rate
    return best_rate

def plot_best_run(actual, predicted, title='Actual vs Predicted'):
    actual = actual.flatten()
    predicted = predicted.flatten()
    plt.figure(figsize=(14,5))
    plt.plot(actual, label='Actual', color='blue')
    plt.plot(predicted, label='Predicted', color='orange')
    plt.title(title)
    plt.xlabel('Time')
    plt.ylabel('Stock Price')
    plt.legend()
    plt.show()

#  Dictionaries to store metrics and success rates
metrics_results = []
success_results = []

#  Train and evaluate for each optimizer
for name, opt in optimizers.items():
    print(f"\nTraining GRU with {name} optimizer...")
    model = build_gru_model((X_train.shape[1],1))
    model.compile(loss='mean_squared_error', optimizer=opt)
    model.fit(X_train, Y_train, epochs=100, batch_size=64, verbose=0)

    # Predictions
    train_pred = model.predict(X_train)
    test_pred = model.predict(X_test)

    # Inverse scale
    train_pred = scaler.inverse_transform(train_pred)
    test_pred = scaler.inverse_transform(test_pred)
    Y_train_scaled = scaler.inverse_transform(Y_train.reshape(-1,1))
    Y_test_scaled = scaler.inverse_transform(Y_test.reshape(-1,1))

    # Metrics
    train_rmse = math.sqrt(mean_squared_error(Y_train_scaled, train_pred))
    test_rmse = math.sqrt(mean_squared_error(Y_test_scaled, test_pred))
    train_mae = mean_absolute_error(Y_train_scaled, train_pred)
    test_mae = mean_absolute_error(Y_test_scaled, test_pred)

    metrics_results.append({
        'Optimizer': name,
        'Train RMSE': train_rmse,
        'Test RMSE': test_rmse,
        'Train MAE': train_mae,
        'Test MAE': test_mae
    })

    # Success rate
    train_avg_success = compute_direction_accuracy(Y_train_scaled, train_pred)
    train_best_success = compute_best_success(Y_train_scaled, train_pred)
    test_avg_success = compute_direction_accuracy(Y_test_scaled, test_pred)
    test_best_success = compute_best_success(Y_test_scaled, test_pred)

    success_results.append({
        'Optimizer': name,
        'Train Avg Success (%)': train_avg_success,
        'Train Best Success (%)': train_best_success,
        'Test Avg Success (%)': test_avg_success,
        'Test Best Success (%)': test_best_success
    })

    # Plot best run for this optimizer
    plot_best_run(Y_test_scaled, test_pred, title=f'{name} Optimizer - Test Best Run (Actual vs Predicted)')


metrics_table = pd.DataFrame(metrics_results)
success_table = pd.DataFrame(success_results)

print("\nRMSE & MAE Comparison Table:")
print(metrics_table)
print("\nAverage & Best Success Rate Table:")
print(success_table)

# Bar graphs for RMSE and MAE
plt.figure(figsize=(10,5))
bar_width = 0.25
x = np.arange(len(metrics_results))

# RMSE bar graph
plt.bar(x - bar_width/2, metrics_table['Test RMSE'], width=bar_width, label='Test RMSE', color='skyblue')
plt.bar(x + bar_width/2, metrics_table['Train RMSE'], width=bar_width, label='Train RMSE', color='orange')
plt.xticks(x, metrics_table['Optimizer'])
plt.ylabel('RMSE')
plt.title('GRU Optimizer Comparison - RMSE')
plt.legend()
plt.show()

# MAE bar graph
plt.figure(figsize=(10,5))
plt.bar(x - bar_width/2, metrics_table['Test MAE'], width=bar_width, label='Test MAE', color='lightgreen')
plt.bar(x + bar_width/2, metrics_table['Train MAE'], width=bar_width, label='Train MAE', color='salmon')
plt.xticks(x, metrics_table['Optimizer'])
plt.ylabel('MAE')
plt.title('GRU Optimizer Comparison - MAE')
plt.legend()
plt.show()